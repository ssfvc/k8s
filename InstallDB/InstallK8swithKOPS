Kubernetes on AWS using Kops
1. Launch Amozon Linux EC2 instance in AWS
2. Create and attach IAM role to EC2 Instance.
Kops need permissions to access
	S3
	EC2
	VPC
	Route53
	Autoscaling
	etc..
3. Install Kops on EC2

$ curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64
$ chmod +x kops-linux-amd64
$ sudo mv kops-linux-amd64 /usr/local/bin/kops
$ kops version


4. Install kubectl

$ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
$ chmod +x ./kubectl
$ sudo mv ./kubectl /usr/local/bin/kubectl


5. Create public  hosted zone in AWS Route53
Head over to aws Route53 and create hostedzone
Choose name for example (maha.in)
Choose type as public hosted zone for VPC
Select default vpc in the region you are setting up your cluster
Hit create


6. Create S3 bucket in AWS
S3 bucket is used by kubernetes to persist cluster state, lets create s3 bucket using aws cli Note: Make sure you choose bucket name that is uniqe accross all aws accounts

$ aws s3 mb s3://mahakube.tk.k8s --region us-east-1

7 Configure environment variables.
Open .bashrc file

$ vi ~/.bashrc

Add following content into .bashrc, you can choose any arbitary name for cluster and make sure buck name matches the one you created in previous step.

export KOPS_CLUSTER_NAME=mahakube.tk
export KOPS_STATE_STORE=s3://mahakube.tk.k8s

Then running command to reflect variables added to .bashrc

$ source ~/.bashrc

8. Create ssh key pair
This keypair is used for ssh into kubernetes cluster

$ ssh-keygen

9. Create a Kubernetes cluster definition.


$ kops create cluster \
--state=${KOPS_STATE_STORE} \
--node-count=2 \
--master-size=t2.micro \
--node-size=t2.micro \
--zones=us-east-1a,us-east-1b \
--name=${KOPS_CLUSTER_NAME} \
--dns public \
--master-count 1


10. Create kubernetes cluster

$ kops update cluster --yes

Above command may take some time to create the required infrastructure resources on AWS. Execute the validate command to check its status and wait until the cluster becomes ready

$ kops validate cluster

For the above above command, you might see validation failed error initially when you create cluster and it is expected behaviour, you have to wait for some more time and check again.

11. To connect to the master
$ ssh admin@api.mahakube.tk



----------------------------
#Dashboard Installation:
----------------------------
#Reference URL: https://github.com/kubernetes/kops/blob/master/docs/addons.md

$ kubectl create -f https://raw.githubusercontent.com/kubernetes/kops/master/addons/kubernetes-dashboard/v1.7.1.yaml


The login credentials are:

    Username: admin
    Password: get by running "kops get secrets kube --type secret -oplaintext" or "kubectl config view --minify"
	
The Dashboard URL pattern is like below:

https://api.$domain/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy/#!/namespace?namespace=_all

As In our case:

https://api.mahakube.tk/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy/#!/namespace?namespace=_all


$ kubectl  create -f admin-dashboard.yaml
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created




 * edit your node instance group with command: kops edit ig --name=domain.com nodes
 * edit your master instance group with command: kops edit ig --name=domain.com master-ap-south-1a
 $ kops update cluster --yes

 Destroy the kubernetes cluster
$ kops delete cluster  --yes
